# Scarlet AI ü§ñ‚ú®

Scarlet is a **privacy-aware, emotionally intelligent, voice-first AI assistant framework** designed to run on both **high-performance systems (Raspberry Pi 5 / PC)** and **low-resource devices (Raspberry Pi Zero 2 W)**.

This repository provides a **sanitized, demo-friendly version** of Scarlet intended for **learning, showcasing architecture, and portfolio/interview purposes**, while keeping sensitive or personal implementations private.

---

## üåü Vision

Scarlet is not just a chatbot, but she is personal companion.

She is designed as:

* A **human-like conversational assistant**
* A **voice-first AI companion**
* A **modular AI platform** for experimentation
* A **safe, controllable, and explainable AI system**

Primary long-term goals include:

* Elder-care and hospital assistance
* Hands-free home AI
* Emotion-aware interactions
* Safe semi-autonomous behaviors

---

## üß† Core Concepts

Scarlet is built around the following principles:

* **Voice First** ‚Äì Wake-word, VAD-based listening, TTS responses
* **Session Awareness** ‚Äì Conversations persist without repeated wake-words
* **Role-Based Behavior** ‚Äì Creator / Known User / Guest logic
* **Emotion & Tone Modeling** ‚Äì Responses adapt to context and user
* **Safety First** ‚Äì Explicit rules, filters, and kill-switch design
* **Hardware-Aware** ‚Äì Same architecture scales from Pi Zero to Pi 5

---

## üß© Projects in the Scarlet Ecosystem

### 1Ô∏è‚É£ Scarlet (Main)

High-capability version designed for:

* Raspberry Pi 5 / PC
* Offline + Online hybrid usage
* Rich TTS (Piper / Google TTS)
* Advanced VAD + Faster-Whisper STT
* Emotion videos / expressions

### 2Ô∏è‚É£ Jasmine (Mini Scarlet)

Lightweight online-only version designed for:

* Raspberry Pi Zero 2 W
* Low memory and CPU
* Groq-hosted Whisper + LLM
* gTTS / lightweight TTS

> This repository primarily focuses on **Scarlet Core Architecture**, with references to Jasmine where relevant.

---

## üèóÔ∏è High-Level Architecture

```
Wake Word Detection
        ‚Üì
Face / User Identification (Optional)
        ‚Üì
Conversation Session Manager
        ‚Üì
Voice Activity Detection (Silero VAD)
        ‚Üì
Speech-to-Text (Faster-Whisper / Groq Whisper)
        ‚Üì
Intent & Behavior Routing
        ‚Üì
LLM (Groq / Mistral / Mock)
        ‚Üì
Response Styling & Emotion Layer
        ‚Üì
Text-to-Speech (Piper / gTTS / Google TTS)
```

---

## üìÅ Repository Structure (Sanitized)

```
scarlet/
‚îú‚îÄ‚îÄ main.py                 # Entry point
‚îú‚îÄ‚îÄ conversation_mode.py    # VAD-based conversation loop
‚îú‚îÄ‚îÄ handler.py              # Intent + role-based routing
‚îú‚îÄ‚îÄ tts.py                  # Text-to-Speech abstraction
‚îú‚îÄ‚îÄ wake_word.py            # Wake word logic (stub/demo)
‚îú‚îÄ‚îÄ memory_mood.py          # Mood & affect tracking
‚îú‚îÄ‚îÄ persona/
‚îÇ   ‚îú‚îÄ‚îÄ persona.yaml        # Assistant personality (sanitized)
‚îÇ   ‚îî‚îÄ‚îÄ rules.yaml          # Behavior & safety rules
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ utils_time.py       # Date & time handling
‚îÇ   ‚îî‚îÄ‚îÄ audio_utils.py
‚îú‚îÄ‚îÄ demo/
‚îÇ   ‚îú‚îÄ‚îÄ mock_llm.py         # Mock LLM for demo mode
‚îÇ   ‚îî‚îÄ‚îÄ mock_tts.py
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

> ‚ö†Ô∏è **Note:** Some internal files (face recognition, private scripts, expression assets) are intentionally excluded.

---

## üîä Speech Stack

### üéôÔ∏è Input (STT)

* **Faster-Whisper** (local, high accuracy)
* **Groq Whisper API** (online, low latency)

### üó£Ô∏è Output (TTS)

* Piper (offline, natural voice)
* gTTS (lightweight)
* Google Cloud TTS (neural voices ‚Äì optional)

---

## üß† LLM Integration

Scarlet supports pluggable LLM backends:

* **Groq API** (Ultra-fast inference)
* **Mistral 7B** (local / self-hosted)
* **Mock LLM** (demo & testing)

LLMs are **never allowed to act directly** ‚Äî all actions pass through:

* Rule filters
* Role checks
* Safety guards

---

## üé≠ Personality & Behavior

Behavior is **configuration-driven**, not hardcoded.

### Role Examples:

* **Creator** ‚Äì Full access
* **Known User** ‚Äì Helpful, respectful
* **Guest** ‚Äì Restricted, safe defaults

### Features:

* Emotional tone mirroring
* Respectful boundaries
* No disclosure of private/internal data
* Context-aware response shaping

---

## üõ°Ô∏è Safety & Control Model

Scarlet is designed with **explicit safety layers**:

* Kill-switch architecture
* Action caps
* Two-step confirmations
* Wake-word & face-gated commands
* Sensor consent rules
* Tool isolation
* Audit-friendly logs

This makes Scarlet suitable for **real-world environments**, not just demos.

---


```
Demo mode uses:

* Mock LLM
* Mock TTS
* Keyboard input fallback

---

## üß™ Who Is This Repo For?

* AI / ML Engineers
* Voice Assistant Developers
* Embedded AI enthusiasts
* Recruiters & Interview Panels
* System architects

---

## üìå What This Repo Is NOT

* ‚ùå A consumer-ready assistant
* ‚ùå A fully autonomous AI
* ‚ùå A jailbreak / uncensored LLM project

This is a **responsible AI system design project**.

---

## üß≠ Roadmap (Public)

* [ ] Barge-in during TTS
* [ ] Unified SSML emotion profiles
* [ ] LED / hardware feedback hooks
* [ ] Better memory TTL handling
* [ ] Plugin-based skills

---

## üë§ Author

**Naga**
AI Engineer | Middleware Architect | Voice AI Systems

> Built as a solo project with a focus on learning, safety, and real-world usability.

---

## üìú License

This project is licensed under the Apache License, Version 2.0.

You may use, modify, and distribute this code in compliance with the Apache-2.0 license.
Attribution and inclusion of the license notice are required.

This repository contains a sanitized, demo-friendly version of the Scarlet project intended for learning, architectural review, and portfolio purposes.

Private extensions, internal assets, datasets, credentials, and personal configurations are not included in this repository and are not covered by this license.

See the LICENSE file for the full license text.

---

## ‚≠ê Final Note

Scarlet represents a **bridge between classic software engineering and modern AI systems** ‚Äî combining discipline, safety, and creativity.

If you are reviewing this repo as part of an interview or evaluation, please treat it as a **system design showcase**, not just a codebase.
